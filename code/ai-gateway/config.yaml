model_list:
    - model_name: llama-distributed
      litellm_params:
        # model: hosted_vllm/mlx-community/Meta-Llama-3-8B-Instruct-4bit
        # api_base: http://host.docker.internal:8080
        # model: hosted_vllm/Qwen/Qwen3-32B
        model: hosted_vllm/Qwen/Qwen3-30B-A3B-Instruct-2507
        api_base: https://ec2-3-36-15-157.ap-northeast-2.compute.amazonaws.com:8443/v1
        api_key: "GreenHorseRedHose2620"
        temperature: 0.0
        stream: true
      model_info:
        supports_function_calling: true

# Register MCP for visibility (agent still connects directly)
mcp_servers:
  fruit_prices:
    url: http://mcp:8000/sse
    transport: sse
    description: "Fruit pricing tool - agent connects directly"

litellm_settings:
  drop_params: true
  ssl_verify: false
  
# For OpenAI
# model_list:
#   - model_name: gpt-4
#     litellm_params:
#       model: gpt-4
#       api_key: os.environ/OPENAI_API_KEY

# # For Anthropic
#   - model_name: claude
#     litellm_params:
#       model: claude-3-sonnet-20240229
#       api_key: os.environ/ANTHROPIC_API_KEY        